# Targets for downloading data used in this analysis

source('1_Download/src/download_helper_fxns.R')
source('1_Download/src/nhdplus_fxns.R')
source('1_Download/src/nwis_fxns.R')
source('1_Download/src/retry_fxns.R')

p1_targets <- list(
  
  # Define target listing the state abbreviations within the Contiguous United States (CONUS)
  tar_target(p1_conus_state_cds, state.abb[!state.abb %in% c('AK', 'HI')]), 
  
  ##### NWIS DATA: Download SC and Q {75 MIN} #####
  
  # All are prefixed with `p1_nwis_`
  
  ###### NWIS DATA 0: Set download configs for streamflow (Q) & specific conductivity (SC) ######
  
  tar_target(p1_nwis_start_date, as.Date('1950-01-01')), 
  tar_target(p1_nwis_end_date, as.Date('2022-12-31')),
  tar_target(p1_nwis_pcode_sc, '00095'), # NWIS specific conductance code
  tar_target(p1_nwis_pcode_q, '00060'), # NWIS streamflow code
  tar_target(p1_nwis_min_years, 10), # Minimum number of years required
  tar_target(p1_nwis_min_end_date, as.Date('2000-01-01')), # Sites must have at least 1 record more recent than this
  
  ###### NWIS DATA 1: Identify sites with continuous SC (by state) ######
  tar_target(p1_nwis_sc_sites_all,
             inventory_nwis_sites_byState(state_cd = p1_conus_state_cds, 
                                          param_cd = p1_nwis_pcode_sc, 
                                          start_date = p1_nwis_start_date,
                                          end_date = p1_nwis_end_date),
             pattern = map(p1_conus_state_cds),
             iteration = 'list'),
  
  ###### NWIS DATA 2: Inventory NWIS & only keep sites with mean daily or instantaneous SC (by state) ######
  tar_target(p1_nwis_sc_data_info, inventory_nwis_data(site_numbers = p1_nwis_sc_sites_all, 
                                                       param_cd = p1_nwis_pcode_sc,
                                                       start_date = p1_nwis_start_date,
                                                       end_date = p1_nwis_end_date),
             pattern = map(p1_nwis_sc_sites_all),
             iteration = 'list'),
  
  ###### NWIS DATA 3: Filter SC sites for `min_yrs` and `min_end_date` (by state) ######
  tar_target(p1_nwis_sc_sites_qualified, 
             filter_to_min_data_standards(p1_nwis_sc_data_info, 
                                          min_yrs = p1_nwis_min_years, 
                                          min_end_date = p1_nwis_min_end_date),
             pattern = map(p1_nwis_sc_data_info),
             iteration = 'list'),
  
  ###### NWIS DATA 4: Identify SC sites that also have mean daily or instantaneous Q (by state) ######
  # The Q data should meet the same minimum data standards as SC. That filtering is combined into
  # a single step below. Notice there is no `iteration = 'list'` because we want the output to be
  # a single table, not a list of tables by state as we have had above.
  tar_target(p1_nwis_q_sites_query,
             inventory_nwis_data(site_numbers = p1_nwis_sc_sites_qualified$site_no, 
                                 param_cd = p1_nwis_pcode_q,
                                 start_date = p1_nwis_start_date,
                                 end_date = p1_nwis_end_date) %>% 
               filter_to_min_data_standards(min_yrs = p1_nwis_min_years, 
                                            min_end_date = p1_nwis_min_end_date),
             pattern = map(p1_nwis_sc_sites_qualified)),
  
  # Using the sites that also have qualified Q, filter the SC site list before querying
  tar_target(p1_nwis_sc_sites_query, p1_nwis_sc_sites_qualified %>% 
               filter(site_no %in% p1_nwis_q_sites_query$site_no),
             pattern = map(p1_nwis_sc_sites_qualified)),
  
  ###### NWIS DATA 5: Prepare to download all the SC data ###### 
  # Separate by the service and download groups. 
  # DV = daily data
  # UV = instantaneous data (downloading only if mean daily values aren't available)
  tar_target(p1_nwis_sc_sites_query_uv, filter(p1_nwis_sc_sites_query, query_service == 'uv')),
  tar_target(p1_nwis_sc_sites_query_uv_download_grps,
             p1_nwis_sc_sites_query_uv %>% 
               # Set `max_results` much lower than default for `uv` because 1 day = 1440 records
               add_download_grp(max_results = 15000) %>% 
               group_by(task_num) %>% 
               tar_group(),
             iteration = 'group'),
  tar_target(p1_nwis_sc_sites_query_dv, filter(p1_nwis_sc_sites_query, query_service == 'dv')),
  tar_target(p1_nwis_sc_sites_query_dv_download_grps,
             p1_nwis_sc_sites_query_dv %>% 
               add_download_grp() %>% 
               group_by(task_num) %>% 
               tar_group(),
             iteration = 'group'),
  
  ###### NWIS DATA 6: Download the SC data and save as files in `1_Download/out_nwis` ######
  
  tar_target(p1_nwis_sc_data_uv_feather,
             download_nwis_data(
               out_file = sprintf('1_Download/out_nwis/sc_uv_%03d.feather',
                                  unique(p1_nwis_sc_sites_query_uv_download_grps$task_num)),
               site_numbers = p1_nwis_sc_sites_query_uv_download_grps$site_no,
               param_cd = p1_nwis_pcode_sc,
               start_date = p1_nwis_start_date,
               end_date = p1_nwis_end_date,
               service_cd = 'uv'
             ),
             pattern = map(p1_nwis_sc_sites_query_uv_download_grps),
             format = 'file'),
  tar_target(p1_nwis_sc_data_dv_feather, 
             download_nwis_data(
               out_file = sprintf('1_Download/out_nwis/sc_dv_%03d.feather', 
                                  unique(p1_nwis_sc_sites_query_dv_download_grps$task_num)),
               site_numbers = p1_nwis_sc_sites_query_dv_download_grps$site_no,
               param_cd = p1_nwis_pcode_sc, 
               start_date = p1_nwis_start_date,
               end_date = p1_nwis_end_date,
               service_cd = 'dv'
             ),
             pattern = map(p1_nwis_sc_sites_query_dv_download_grps),
             format = 'file'),
  
  ###### NWIS DATA 7: Prepare to download all the Q data ###### 
  # Separate by the service and download groups.
  # DV = daily data
  # UV = instantaneous data (downloading only if mean daily values aren't available
  tar_target(p1_nwis_q_sites_query_uv, filter(p1_nwis_q_sites_query, query_service == 'uv')),
  tar_target(p1_nwis_q_sites_query_uv_download_grps,
             p1_nwis_q_sites_query_uv %>% 
               # Set `max_results` much lower than default for `uv` because 1 day = 1440 records
               add_download_grp(max_results = 15000) %>% 
               group_by(task_num) %>% 
               tar_group(),
             iteration = 'group'),
  tar_target(p1_nwis_q_sites_query_dv, filter(p1_nwis_q_sites_query, query_service == 'dv')),
  tar_target(p1_nwis_q_sites_query_dv_download_grps,
             p1_nwis_q_sites_query_dv %>% 
               add_download_grp() %>% 
               group_by(task_num) %>% 
               tar_group(),
             iteration = 'group'),
  
  ###### NWIS DATA 8: Download the Q data and save as files in `1_Download/out_nwis` ######
  tar_target(p1_nwis_q_data_uv_feather,
             download_nwis_data(
               out_file = sprintf('1_Download/out_nwis/q_uv_%03d.feather',
                                  unique(p1_nwis_q_sites_query_uv_download_grps$task_num)),
               site_numbers = p1_nwis_q_sites_query_uv_download_grps$site_no,
               param_cd = p1_nwis_pcode_q,
               start_date = p1_nwis_start_date,
               end_date = p1_nwis_end_date,
               service_cd = 'uv'
             ),
             pattern = map(p1_nwis_q_sites_query_uv_download_grps),
             format = 'file'),
  tar_target(p1_nwis_q_data_dv_feather, 
             download_nwis_data(
               out_file = sprintf('1_Download/out_nwis/q_dv_%03d.feather', 
                                  unique(p1_nwis_q_sites_query_dv_download_grps$task_num)),
               site_numbers = p1_nwis_q_sites_query_dv_download_grps$site_no,
               param_cd = p1_nwis_pcode_q, 
               start_date = p1_nwis_start_date,
               end_date = p1_nwis_end_date,
               service_cd = 'dv'
             ),
             pattern = map(p1_nwis_q_sites_query_dv_download_grps),
             format = 'file'),
  
  ###### NWIS DATA 9: Download site metadata ######
  
  tar_target(p1_nwis_sc_sites_metadata,
             download_nwis_metadata(p1_nwis_sc_sites_query$site_no)),
  
  ##### SCIENCEBASE DATASET DOWNLOADS {< 1 MIN} #####
  
  # All are prefixed with `p1_sb_`
  
  # All ScienceBase (SB) datasets can be visited on SB by visiting the URL
  #   `https://www.sciencebase.gov/catalog/item/{ITEM ID}` and input the 
  #   item id for each dataset at the end of the URL.
  
  ###### SB DATA 1: Road salt application rates (Falcone et al., 2018) ######
  
  # Falcone, J. A., Oelsner, G. P., and Bock, A. R. (2018). Estimates of Road
  #   Salt Application across the conterminous United States (1992-2015).
  
  # Have to download the full zipfile but will only be using the 2015 
  # gridded road salt application rates raster file
  
  tar_target(p1_sb_road_salt_zip, 
             item_file_download(sb_id = '5b15a50ce4b092d9651e22b9',
                                names = '1992_2015.zip',
                                destinations = '1_Download/tmp/road_salt_all.zip'),
             format = 'file'),
  tar_target(p1_sb_road_salt_2015_tif, 
             extract_file_from_zip(out_file = '1_Download/out/road_salt_2015.tif', 
                                   zip_file = p1_sb_road_salt_zip,
                                   file_to_extract = '2015.tif'), 
             format = 'file'),
  
  ###### SB DATA 2: Gridded groundwater attributes (Zell and Sanford, 2020) ######
  # Includes transmissivity and depth to water table
  
  # Zell, W. O., Sanford, W. E. (2020). Calibrated simulation of the long‐term average
  #   surficial groundwater system and derived spatial distributions of its characteristics 
  #   for the contiguous United States. Water Resources Research, 55, e2019WR026724. 
  #   https://doi.org/10.1029/2019WR026724.
  
  tar_target(p1_sb_transmissivity_csv, 
             item_file_download(sb_id = '60be54f6d34e86b9389117f9',
                                names = 'trans.csv',
                                destinations = '1_Download/out/transmissivity.csv'), 
             format = 'file'),
  tar_target(p1_sb_depth2wt_csv, 
             item_file_download(sb_id = '60be54f6d34e86b9389117f9',
                                names = 'dtw.csv',
                                destinations = '1_Download/out/depth2wt.csv'), 
             format = 'file'),
  
  ##### ADDITIONAL DATASETS ONLINE {< 1 MIN} #####
  
  # Hare, D. K., Helton, A. M., Johnson, Z. C., Lane, J. W., and Briggs, M. A. (2021). 
  #   Continental-scale analysis of shallow and deep groundwater contributions to streams.
  #   Nature Communications, 12(1):1450. Number: 1 Publisher: Nature Publishing Group.
  
  # The groundwater signature dataset from Hare et al. 2021 is available for download on
  # nature.com. The following targets download the zipfile and unzip, keeping the needed files.
  tar_target(p1_url_gwsig_zip, 
             download_file_from_url(out_file = '1_Download/tmp/gwsig.zip',
                                    url_in = 'https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-021-21651-0/MediaObjects/41467_2021_21651_MOESM3_ESM.zip'),
             format = 'file'),
  tar_target(p1_url_gwsig_xlsx, 
             extract_file_from_zip(out_file = '1_Download/out/gwsig.xlsx', 
                                   zip_file = p1_url_gwsig_zip,
                                   file_to_extract = 'sourcedatafigs1,2and3.xlsx'), 
             format = 'file'),
  
  ##### NHD+: Identify COMIDs for USGS NWIS sites & download catchment attributes {?? MIN} #####
  
  ###### Link stream sites to COMIDs #####
  
  # First, turn sites into a spatial features object and group into sets of 100 sites
  # in preparation for querying NHDPlus
  tar_group_size(p1_nwis_sc_sites_sf, 
                 fetch_site_locations(p1_nwis_sc_sites_metadata),
                 size = 50),
  
  # Then, query NHDPlus using the site locations to identify
  # the NHD COMID of the closest reach. Two of the COMIDs are 
  # reused for the same sites:
  #   COMID 5866457 is linked to site_no '01104455' and '01104460'
  #   COMID 11079215 is linked to site_no '07381324' and '07381328'
  tar_target(p1_nwis_site_nhd_comid_xwalk, 
             identify_site_comids(p1_nwis_sc_sites_sf),
             pattern = map(p1_nwis_sc_sites_sf)),
  
  ###### Download desired static catchment attributes from NHDPlus #####
  
  # Wieczorek, M.E., Jackson, S.E., and Schwarz, G.E., 2018, Select Attributes for 
  #   NHDPlus Version 2.1 Reach Catchments and Modified Network Routed Upstream Watersheds 
  #   for the Conterminous United States (ver. 4.0, August 2023): U.S. Geological Survey 
  #   data release, https://doi.org/10.5066/F7765D7V.
  
  # NHDPlus reach and catchment attributes originating from Wieczorek et al., 2018 but
  # downloaded via functions in the `nhdplusTools` R package.
  tar_target(p1_nhdplus_attr_yml, '1_Download/in/nhdplus_attributes.yml', format='file'),
  tar_target(p1_nhdplus_attr_list, load_nhdplus_attribute_list(p1_nhdplus_attr_yml)),
  
  # Download catchment attributes data for each COMID
  tar_target(p1_nhdplus_attr_vals_tbl, 
             download_nhdplus_attributes(attributes = unlist(p1_nhdplus_attr_list),
                                         comids = unique(p1_nwis_site_nhd_comid_xwalk$nhd_comid)),
             pattern = map(p1_nhdplus_attr_list))
  
)
